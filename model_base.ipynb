{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b5a5864-1a30-4e2f-815e-b2b64d392834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiny_utils # custom module\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from train import UNET\n",
    "from tiny_utils import ShipDatabaseSegmation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.morphology import binary_opening, disk, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d06070f-3af6-4995-9fe7-d66cfdc409f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "base_model = model.load_state_dict(torch.load(\"base_model_checkpoint.pth.tar\")['state_dict']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae4da053-8f5f-458d-be2f-fbaa6b3bd11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9704 training set\n",
      "511 validation set\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "data = pd.read_csv(\"data/train_ship_segmentations_v2.csv\")\n",
    "data = data.dropna() \n",
    "data = data.sample(frac=0.125, replace=False, random_state=42)\n",
    "\n",
    "train, valid = train_test_split(data, test_size = 0.05, random_state=42)\n",
    "print(train.shape[0], 'training set')\n",
    "print(valid.shape[0], 'validation set')\n",
    "\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor() \n",
    "])\n",
    "ship_dataset_train = ShipDatabaseSegmation(train, \"data/train_v2\", transforms=transforms)\n",
    "ship_dataset_valid = ShipDatabaseSegmation(valid, \"data/train_v2\", transforms=transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(ship_dataset_train, batch_size=5, shuffle=True, num_workers=8)\n",
    "valid_loader = torch.utils.data.DataLoader(ship_dataset_valid, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e4add-2bce-466c-9cb6-47f89e305e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422c7f5-5525-43e4-911b-a5178b248893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: 100%|███████████████████████████████████████████████████████████| 508/508 [01:40<00:00,  5.08it/s, bceWithLogitLoss - 0.03445, iou_score - 7.982e-10]\n",
      "valid:  21%|████████████                                              | 352/1690 [06:18<23:54,  1.07s/it, bceWithLogitLoss - 0.03504, iou_score - 2.412e-11]"
     ]
    }
   ],
   "source": [
    "# loading U-Net Layer to Base UNET\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "loss.__name__ = \"bceWithLogitLoss\"\n",
    "device = \"cuda\"\n",
    "metrics = [smp.utils.metrics.IoU(threshold=0.5),]\n",
    "\n",
    "test_epoch_UNET = smp.utils.train.ValidEpoch(model, \n",
    "                                            loss=loss, \n",
    "                                            metrics=metrics, \n",
    "                                            device=device,\n",
    "                                            verbose=True,)\n",
    "\n",
    "valid_logs = test_epoch_UNET.run(valid_loader) #  on data validation\n",
    "train_logs = test_epoch_UNET.run(train_loader) #  on data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62994809-3715-4c08-82be-1f2aa3114b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# terrible IoU scores. Further parameter tweaking is needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e47ae6-80bd-4c34-8606-da0525ac70f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
